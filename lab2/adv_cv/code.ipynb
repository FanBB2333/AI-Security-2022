{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452a05ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aisec/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c99771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mobile and simple cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8492bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8005273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "        net = models.mobilenet_v3_small(pretrained=False)\n",
    "        \n",
    "        self.trunk = nn.Sequential(*(list(net.children())[:-2]))\n",
    "        \n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(576, 10, bias=True),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.trunk(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "\n",
    "    no_cuda = False\n",
    "    seed = 1111\n",
    "    batch_size = 128\n",
    "    test_batch_size = 1000\n",
    "    lr = 0.01\n",
    "    save_model = True\n",
    "    epochs = 2\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': batch_size,'shuffle':True}\n",
    "    test_kwargs = {'batch_size': test_batch_size,'shuffle':True}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': False}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.ImageFolder('mnist/training',transform=transform)\n",
    "    dataset2 = datasets.ImageFolder('mnist/testing',transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs,)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    #model = MobileNet().to(device)\n",
    "        \n",
    "    optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train( model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "        #torch.save(model.state_dict(), \"mnist_mobile.pt\")\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d564ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.213348\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 4.161409\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.100485\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.855450\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.402011\n",
      "\n",
      "Test set: Average loss: 4.3814, Accuracy: 1009/10000 (10%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 5.734994\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 4.088257\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 3.808168\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.673404\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.358253\n",
      "\n",
      "Test set: Average loss: 2.9362, Accuracy: 1009/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d668414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6877580190>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "four_img = Image.open(\"mnist/pic/4.jpg\")\n",
    "four_img = four_img.convert('RGB')\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor()  \n",
    "        ])\n",
    "\n",
    "norm=transforms.Compose([\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "\n",
    "four_tensor = transform(four_img)[None,:,:,:]\n",
    "\n",
    "# plot image (note that numpy using HWC whereas Pytorch user CHW, so we need to convert)\n",
    "plt.imshow(four_tensor[0].numpy().transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d32abf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_tensor = four_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5c63cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cnn_eval(tensor):\n",
    "    model=Net().to(device)\n",
    "    model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
    "    model.eval()\n",
    "    print(torch.argmax(model(tensor)))\n",
    "\n",
    "def mobile_eval(tensor):\n",
    "    model=MobileNet().to(device)\n",
    "    model.load_state_dict(torch.load(\"mnist_mobile.pt\"))\n",
    "    model.eval()\n",
    "    print(torch.argmax(model(tensor)))\n",
    "\n",
    "mobile_eval(norm(four_tensor))\n",
    "cnn_eval(norm(four_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd4a26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fgsm to get a wrong prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dedcbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.9055, -3.7858, -3.6674, -3.5200, -3.3522, -3.1603, -2.8948, -2.5164,\n",
       "         -1.8306, -0.6382]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2102e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.3522, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(9, device='cuda:0')\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6875ff0d00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt = 4\n",
    "delta = torch.zeros_like(four_tensor, requires_grad=True).to(device)\n",
    "opt = optim.SGD([delta], lr=10)\n",
    "epsilon = 0.2\n",
    "for t in range(20):\n",
    "    pred = model(norm(four_tensor + delta))\n",
    "\n",
    "    loss = -nn.CrossEntropyLoss()(pred, torch.LongTensor([gt]).to(device))\n",
    "    \n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    delta.data.clamp_(-epsilon, epsilon)\n",
    "print(loss)\n",
    "print(cnn_eval(norm(four_tensor + delta)))\n",
    "plt.imshow(norm(four_tensor + delta)[0].detach().cpu().numpy().transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5856191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgd more powerful \n",
    "# targeted attack: control model to give a target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b0b45b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eaf0cb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0 0.15446233749389648\n",
      "50 0.15446233749389648\n",
      "100 0.15446233749389648\n",
      "150 0.15446233749389648\n",
      "200 0.15446233749389648\n",
      "250 0.15446233749389648\n",
      "300 0.15446233749389648\n",
      "350 0.15446233749389648\n",
      "400 0.15446233749389648\n",
      "450 0.15446233749389648\n",
      "True class probability: tensor([[0.0201, 0.0227, 0.0255, 0.0296, 0.0350, 0.0424, 0.0553, 0.0807, 0.1603,\n",
      "         0.5282]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model.eval()\n",
    "def l_infinity_pgd(model, tensor, gt,epsilon=40./255, target=None,iteration=500, show=True):\n",
    "    tensor = tensor.to(device)\n",
    "    delta = torch.zeros_like(tensor).to(device)\n",
    "    delta.requires_grad=True\n",
    "    opt = optim.SGD([delta], lr=0.1)\n",
    "    print(target)\n",
    "    for t in range(iteration):\n",
    "        pred = model(norm(tensor + delta))\n",
    "        if target is None:\n",
    "            loss = -nn.CrossEntropyLoss()(pred, torch.LongTensor([gt]).to(device))\n",
    "        else:\n",
    "\n",
    "            loss = - 0.5 * nn.CrossEntropyLoss()(pred, torch.LongTensor([4]).to(device)) + nn.CrossEntropyLoss()(pred, torch.LongTensor([target]).to(device))\n",
    "        if t % 50 == 0:\n",
    "            print(t, loss.item())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        delta.data.clamp_(-epsilon, epsilon)\n",
    "\n",
    "    print(\"True class probability:\", nn.Softmax(dim=1)(pred))\n",
    "    cnn_eval(norm(tensor+delta))\n",
    "\n",
    "    if show:\n",
    "        f,ax = plt.subplots(1,2, figsize=(10,5))\n",
    "        ax[0].imshow((delta)[0].detach().cpu().numpy().transpose(1,2,0))\n",
    "        ax[1].imshow((tensor + delta)[0].detach().cpu().numpy().transpose(1,2,0))\n",
    "    \n",
    "    return tensor + delta\n",
    "\n",
    "x= l_infinity_pgd(model,four_tensor,4,target=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 是不是像才可以？铁男都可以是数字？？？ 其实图片越复杂，对抗扰动就越难以察觉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2792bf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6874331a30>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "rem_img = Image.open(\"mnist/pic/tienan.jpeg\")\n",
    "rem_img = rem_img.convert('RGB')\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((28,28))  ,\n",
    "        transforms.ToTensor()  \n",
    "        ])\n",
    "\n",
    "norm=transforms.Compose([\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "\n",
    "rem_tensor = transform(rem_img)[None,:,:,:]\n",
    "cnn_eval(norm(rem_tensor.to(device)))\n",
    "plt.imshow(rem_tensor[0].cpu().numpy().transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21846f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53bf31b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0 1.2186567783355713\n",
      "50 1.2186567783355713\n",
      "100 1.2186567783355713\n",
      "True class probability: tensor([[0.0201, 0.0227, 0.0255, 0.0296, 0.0350, 0.0424, 0.0553, 0.0807, 0.1603,\n",
      "         0.5282]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9961, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 0.9882, 0.7725,  ..., 0.7843, 0.9882, 1.0000],\n",
       "          [1.0000, 0.9608, 0.2941,  ..., 0.4196, 0.9020, 0.9686],\n",
       "          [0.9961, 0.9608, 0.2784,  ..., 0.3412, 0.9294, 0.9765]],\n",
       "\n",
       "         [[0.4706, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4745],\n",
       "          [0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4745],\n",
       "          [0.4667, 0.4667, 0.4667,  ..., 0.4667, 0.4667, 0.4745],\n",
       "          ...,\n",
       "          [0.4667, 0.4627, 0.3725,  ..., 0.3765, 0.4627, 0.4745],\n",
       "          [0.4667, 0.4510, 0.1451,  ..., 0.3098, 0.5412, 0.4980],\n",
       "          [0.4745, 0.4588, 0.1451,  ..., 0.2157, 0.4980, 0.4902]],\n",
       "\n",
       "         [[0.0078, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0157],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0157],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0157],\n",
       "          ...,\n",
       "          [0.0039, 0.0078, 0.0275,  ..., 0.0314, 0.0118, 0.0196],\n",
       "          [0.0039, 0.0078, 0.0275,  ..., 0.2157, 0.1922, 0.0824],\n",
       "          [0.0157, 0.0196, 0.0353,  ..., 0.1176, 0.1059, 0.0627]]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "# 注意修改gt为输出值\n",
    "pred = 9\n",
    "l_infinity_pgd(model,rem_tensor,pred,20./255,6,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de111ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一视角 各种算法 \n",
    "# 1) the norm ball perturbation they consider, \n",
    "# 2) the method they use for optimizing over that norm ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac9963e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer attack 使用simple cnn产生的攻击样本，对mobile会有影响吗？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5bc445c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         save_image(adv_img, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir_1,\u001b[38;5;28mstr\u001b[39m(batch_idx)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     31\u001b[0m         save_image(adv_img, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir_2,\u001b[38;5;28mstr\u001b[39m(batch_idx)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 33\u001b[0m \u001b[43mcreate_adv_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36mcreate_adv_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_cnn.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 22\u001b[0m adv_img \u001b[38;5;241m=\u001b[39m \u001b[43ml_infinity_pgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m35.\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mattack_target\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m image_dir_1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist/adv_ori_label\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(target\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m     24\u001b[0m image_dir_2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist/adv_adv_label\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(attack_target))\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36ml_infinity_pgd\u001b[0;34m(model, tensor, gt, epsilon, target, iteration, show)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(target)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iteration):\n\u001b[0;32m---> 11\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(pred, torch\u001b[38;5;241m.\u001b[39mLongTensor([gt])\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    393\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    394\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "def create_adv_dataset():\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    dataset1 = datasets.ImageFolder('mnist/training',transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,batch_size=1, shuffle=True, num_workers=8)\n",
    "    \n",
    "    attack_target = 0 \n",
    "    # 每个数字生成100个对抗样本\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        attack_target = batch_idx//100\n",
    "        if target== attack_target:\n",
    "            continue\n",
    "        if attack_target>9:\n",
    "            break\n",
    "        model=Net()\n",
    "        model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
    "        model.eval()\n",
    "        adv_img = l_infinity_pgd(model,data,target,35./255,attack_target,50,False)\n",
    "        image_dir_1 = os.path.join('mnist/adv_ori_label',str(target.item()))\n",
    "        image_dir_2 = os.path.join('mnist/adv_adv_label',str(attack_target))\n",
    "        if not os.path.exists(image_dir_1):\n",
    "            os.makedirs(image_dir_1)\n",
    "        if not os.path.exists(image_dir_2):\n",
    "            os.makedirs(image_dir_2)\n",
    "        \n",
    "        save_image(adv_img, os.path.join(image_dir_1,str(batch_idx)+'.jpg'))\n",
    "        save_image(adv_img, os.path.join(image_dir_2,str(batch_idx)+'.jpg'))\n",
    "\n",
    "create_adv_dataset()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f23ae154",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_cnn.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# test(model, 'cpu', test_loader2)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m=\u001b[39mMobileNet()\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     80\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 81\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# sum up batch loss\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aisec/lib/python3.9/site-packages/torch/nn/modules/conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    393\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    394\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "test_transform=transforms.Compose([\n",
    "        #transforms.GaussianBlur(3, sigma=(0.1, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "  \n",
    "dataset1 = datasets.ImageFolder('mnist/testing',transform=test_transform)\n",
    "dataset2 = datasets.ImageFolder('mnist/adv_ori_label',transform=test_transform)\n",
    "test_loader1 = torch.utils.data.DataLoader(dataset1, shuffle=False,batch_size=100)\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset2, shuffle=False,batch_size=100)\n",
    "\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test(model,device, test_loader1)\n",
    "# test(model, 'cpu', test_loader2)\n",
    "\n",
    "model=MobileNet()\n",
    "model.load_state_dict(torch.load(\"mnist_mobile.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# test(model, 'cpu', test_loader1)\n",
    "# test(model, 'cpu', test_loader2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25971a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial examples may be features train a net using adv_adv_label\n",
    "# 参看课件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98077031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defense\n",
    "# denoise renoise \n",
    "# detection \n",
    "# adversrial training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisec",
   "language": "python",
   "name": "aisec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
